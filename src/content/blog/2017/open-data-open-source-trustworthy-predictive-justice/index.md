---
title: "Published my first paper about Trustworthy Predictive Justice"
description: "Peerâ€‘reviewed publication at JOAL (Cornell): predictive justice is credible only if both the data and the code are open. A French court study shows an interpretable 87.2% model; code and dataset released for scrutiny."
pubDatetime: 2017-06-17T00:00:00.000Z
draft: false
author: "MichaÃ«l Benesty"
tags: ["Open Data", "Open Source", "Justice", "Machine Learning", "Legaltech"]
postSlug: 2017/open-data-open-source-trustworthy-predictive-justice
---

> Published in the **Journal of Open Access to Law (JOAL)**, hosted at Cornell Law School.  
> **DOI:** https://doi.org/10.63567/34drrn20 Â· **PDF:** https://ojs.law.cornell.edu/index.php/joal/article/download/61/68

# Published my first paper about Trustworthy Predictive Justice

**Thesis:** predictive justice is only credible if both the **data** and the **code** are open to scrutiny. Blackâ€‘box â€œpredictionsâ€ donâ€™t meet professional standards for lawyers or judges.

In a largeâ€‘scale experiment on more than **18,000** decisions from French administrative courts of appeal (2012â€“2015), a supervised ML model (XGBoost) predicts outcomes in the immigrationâ€‘removal docket with **87.2%** accuracy *and* remains interpretable enough for legal professionals to audit. Among the practical signals: noting that a litigant has **legal aid** increases the likelihood of annulment, while the **identity of the presiding judge** adds little predictive power. The project releases the model, code, and annotated dataset openly so others can verify, reuse, and critique.

ğŸ‘‰ **Read the paper** (French): [*Lâ€™open data et lâ€™open source, des soutiens nÃ©cessaires Ã  une justice prÃ©dictive fiable?*](/files/papers/open-data-open-source-trustworthy-predictive-justice.pdf)
